{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT Training Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use LaTeX style for text rendering\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Computer Modern']\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rcParams['text.latex.preamble'] = r'\\usepackage{amsmath}\\usepackage{amsfonts}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-2 (124M) Loss after 100B tokens\n",
    "gpt2_loss = 3.2924\n",
    "\n",
    "# GPT-2 (124M) and GPT-3 (125M) HellaSwag acc after 100B and 300B tokens respectively\n",
    "gpt2_hs = 0.294\n",
    "gpt3_hs = 0.337\n",
    "\n",
    "log_file = 'model.txt'\n",
    "\n",
    "colour = '#4287f5'\n",
    "\n",
    "# Read the log file, group by stream name ('train', 'val', 'hella', 'ckpt')\n",
    "streams = {}\n",
    "with open(os.path.join('../cache/', log_file), 'r') as f:\n",
    "    for line in f:\n",
    "        step, n_tokens, stream, val = line.strip().split()\n",
    "        if stream not in streams:\n",
    "            streams[stream] = ([], [])\n",
    "        streams[stream][0].append(int(n_tokens[1:-1]))\n",
    "        streams[stream][1].append(float(val))\n",
    "\n",
    "# Train and Validation Loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(*streams['train'], color=colour, alpha=0.5, label=r'GPT-$\\alpha$ 124M Loss (Train)')\n",
    "plt.plot(*streams['val'], color=colour, label=r'GPT-$\\alpha$ 124M Loss (Val)')\n",
    "# Plot the GPT-2 loss baseline\n",
    "plt.axhline(y=gpt2_loss, color='grey', linestyle='--', label='OpenAI GPT-2 124M Loss (Val)')\n",
    "# Plot latest checkpoint\n",
    "plt.plot(streams['ckpt'][0][-1:], streams['ckpt'][1][-1:], color='#4287f5', marker='v', linestyle='None', label='Latest Checkpoint')\n",
    "plt.xlabel('Tokens')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(top=4.0)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'../cache/{log_file[:-4]}_loss.pdf')\n",
    "plt.show()\n",
    "\n",
    "# HellaSwag Evaluation\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(*streams['hella'], color=colour, label=r'GPT-$\\alpha$ 124M')\n",
    "# Plot the GPT-2 and GPT-3 HellaSwag checkpoints\n",
    "plt.axhline(y=gpt2_hs, color='grey', linestyle='--', label='OpenAI GPT-2 124M')\n",
    "plt.axhline(y=gpt3_hs, color='grey', linestyle='-.', label='OpenAI GPT-3 125M')\n",
    "plt.xlabel('Tokens')\n",
    "plt.ylabel('HellaSwag Accuracy')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'../cache/{log_file[:-4]}_hs.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the minimum validation loss\n",
    "min_val = min(streams['val'][1])\n",
    "min_val_idx = streams['val'][1].index(min_val)\n",
    "min_val_tokens = streams['val'][0][min_val_idx]\n",
    "print(f'Minimum Validation Loss: {min_val:.3f} @ {min_val_tokens:,} (GPT-2: {gpt2_loss:.3f})')\n",
    "\n",
    "# Print the maximum HellaSwag accuracy\n",
    "max_hs = max(streams['hella'][1])\n",
    "max_hs_idx = streams['hella'][1].index(max_hs)\n",
    "max_hs_tokens = streams['hella'][0][max_hs_idx]\n",
    "print(f'Maximum HellaSwag accuracy: {max_hs:.3f} @ {max_hs_tokens:,} (GPT-2: {gpt2_hs:.3f}, GPT-3: {gpt3_hs:.3f})')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
